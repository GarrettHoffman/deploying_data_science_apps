{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training / Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define our inputs\n",
    "\n",
    "# data related inputs\n",
    "train_data_dir = '../data/train'\n",
    "validation_data_dir = '../data/val'\n",
    "nb_train_samples = len(glob.glob('../data/train/chart/*'))+len(glob.glob('../data/train/meme/*'))\n",
    "nb_validation_samples = len(glob.glob('../data/val/chart/*'))+len(glob.glob('../data/val/meme/*'))\n",
    "\n",
    "# training related inputs\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "img_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# definte data generators\n",
    "\n",
    "# can define data augmentations here, we will scale images values between 0 and 1\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "val_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# this is a generator that will read pictures found in\n",
    "# subfolers of 'data/train', and indefinitely generate\n",
    "# batches of augmented image data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        '../data/train',  # this is the target directory\n",
    "        batch_size=batch_size,\n",
    "        target_size=(img_size, img_size),\n",
    "        class_mode='binary')\n",
    "\n",
    "# this is a similar generator, for validation data\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "        '../data/val',\n",
    "        batch_size=batch_size,\n",
    "        target_size=(img_size, img_size),\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/GarrettHoffman/anaconda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/GarrettHoffman/anaconda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# now we define our model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(img_size, img_size, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 248, 248, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 248, 248, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 124, 124, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 122, 122, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 122, 122, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 61, 61, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 59, 59, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 59, 59, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 53824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                3444800   \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,473,505\n",
      "Trainable params: 3,473,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# view model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/GarrettHoffman/anaconda/envs/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "4/4 [==============================] - 2s 494ms/step - loss: 0.7187 - acc: 0.5700\n",
      "32/32 [==============================] - 47s 1s/step - loss: 1.0195 - acc: 0.5840 - val_loss: 0.7187 - val_acc: 0.5700\n",
      "Epoch 2/5\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 0.3700 - acc: 0.8400\n",
      "32/32 [==============================] - 47s 1s/step - loss: 0.5084 - acc: 0.7690 - val_loss: 0.3700 - val_acc: 0.8400\n",
      "Epoch 3/5\n",
      "4/4 [==============================] - 2s 481ms/step - loss: 0.2658 - acc: 0.9100\n",
      "32/32 [==============================] - 45s 1s/step - loss: 0.3705 - acc: 0.8480 - val_loss: 0.2658 - val_acc: 0.9100\n",
      "Epoch 4/5\n",
      "4/4 [==============================] - 2s 481ms/step - loss: 0.2786 - acc: 0.8700\n",
      "32/32 [==============================] - 46s 1s/step - loss: 0.3181 - acc: 0.8840 - val_loss: 0.2786 - val_acc: 0.8700\n",
      "Epoch 5/5\n",
      "4/4 [==============================] - 2s 467ms/step - loss: 0.2226 - acc: 0.9300\n",
      "32/32 [==============================] - 45s 1s/step - loss: 0.2131 - acc: 0.9380 - val_loss: 0.2226 - val_acc: 0.9300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x134cc2438>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# this is a similar generator, for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        '../data/test',\n",
    "        batch_size=batch_size,\n",
    "        target_size=(img_size, img_size),\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Loss: 0.2255668118596077\n",
      "Test Set Accuracy: 0.8700000047683716\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the holdout test set\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator)\n",
    "print(f\"Test Set Loss: {test_loss}\")\n",
    "print(f\"Test Set Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85162807]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference on signle image\n",
    "\n",
    "img = cv2.imread(\"../data/awesome_chart.png\", 1)\n",
    "img = cv2.resize(img, (250, 250))\n",
    "img = img / 255\n",
    "\n",
    "# need to add additional dimention because model expects a batch\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "model.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model For Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the model for service\n",
    "model.save('../api/cv_chart_model.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
